{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classifiers\n",
    "\n",
    "Today, we will be examining classifiers using an EEG dataset from Michelle's lab using a boundary-based classification method (support vector machine) as well as cross validation.\n",
    "\n",
    "By the end of today's lesson, you should know how to implement various types of K-fold cross validation, as well as understand the accuracy and time tradeoffs in each.\n",
    "\n",
    "Let's start by reading in the data - please be patient because it's a big file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# Load in the data file\n",
    "dataMat = loadmat('/home/data/eegData/sim001_bootstrap.mat')\n",
    "dataMat = dataMat['data']\n",
    "\n",
    "# Load in the category labels\n",
    "trialData = loadmat('/home/data/eegData/sub001.mat')\n",
    "trialData = trialData['catVec']\n",
    "trialData = trialData[6:,0] # Here, the first 6 trials were practice and can be discarded\n",
    "\n",
    "print(trialData.shape)\n",
    "print(dataMat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are 63 electrodes, 600 time points, and 1200 trials. In this experiment, observers saw 100 repeats each of 12 different scene categories. Time 0 refers to 100 ms before stimulus onset, so we have 500 ms of stimulus-driven response.\n",
    "\n",
    "A powerful way to use classifiers in EEG is to perform the analysis at each time point. This can show us when there is neural information in the scene categories over time. However, it takes a long time to run classifiers on each time point! In the interest of time, we will isolate time point 200 (101 ms after image onset). This should yield a 63-electrode by 1200-trial array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time200 = # fill me in: should be 63x1200 array when printed\n",
    "print(time200.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it's a good intellectual exercise to work through creating different train-test splits of your data, I'm going to let you off easy today. We'll be using a built-in machine learning function to do k-fold cross validation. Run this cell to get the gist of how train and test splits work for this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# create a list of indices for all 1200 trials\n",
    "allIndices = np.arange(1200)\n",
    "\n",
    "# create a k-fold object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# for each train-test split, print the length of train and test indices\n",
    "for trainIdx, testIdx in kf.split(allIndices):\n",
    "    print(len(trainIdx), len(testIdx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that in each of the five folds, there are 960 trials that will be used to train the classifier, and 240 trials that will be used to test the classifier. Now, we are ready to apply this information to performing a 5-fold cross validation of this data! Fill in the code below to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import svm from machine learning library\n",
    "from sklearn import svm\n",
    "\n",
    "# initialize accuracy vector (hint: should be the number of folds)\n",
    "overallAccuracy = np.zeros()\n",
    "\n",
    "# initialize a counter for the folds\n",
    "foldCount = -1\n",
    "\n",
    "# loop through all folds\n",
    "for trainIdx, testIdx in kf.split(allIndices):\n",
    "    # increment counter\n",
    "    foldCount += 1\n",
    "    \n",
    "    # initialize vector that will hold a 1 (accurate) or a 0 (inaccurate) value for each of the test items\n",
    "    foldAccuracy = np.zeros()\n",
    "    \n",
    "    # define training data: fill in square brackets to indicate the trial indices for the given fold for training\n",
    "    trainData = time200[].T\n",
    "    # define training answers\n",
    "    trainAnswers = trialData[]\n",
    "    \n",
    "    # define testing data: fill in square brackets to indicate the trial indices for the given fold for testing\n",
    "    testData = time200[].T\n",
    "    # define testing answers\n",
    "    testAnswers = trialData[]\n",
    "    \n",
    "    # define the classifier\n",
    "    classifier = svm.SVC(kernel = 'linear')\n",
    "    \n",
    "    # train the classifier\n",
    "    classifier.fit(trainData, trainAnswers)\n",
    "    \n",
    "    # test the classifier\n",
    "    predClass = classifier.predict(testData)\n",
    "    \n",
    "    # loop through each of the predicted classes and test whether they are correct\n",
    "    for i in range(len(predClass)):\n",
    "        if predClass[i]==testAnswers[i]: \n",
    "            foldAccuracy[i] = 1\n",
    "            \n",
    "    overallAccuracy[foldCount] = np.mean(foldAccuracy)\n",
    "\n",
    "# print the average accuracy over all folds\n",
    "print(np.mean(overallAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A randomly-guessing classifier would get, on average, 1/12 items correct (0.08). Considering this, it's not bad performance! You may be wondering what's so great about 5-fold cross validation and whether better performance might be observed with other values of K. \n",
    "\n",
    "In the cell(s) below, play around with other values of K and observe the accuracy as well as the time necessary to obtain a result. Discuss with your group what the optimal value might be (if there is any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer_workshop",
   "language": "python",
   "name": "summer_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
