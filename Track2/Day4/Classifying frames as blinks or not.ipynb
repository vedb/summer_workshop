{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import file_io\n",
    "import plot_utils\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "import sklearn\n",
    "import glob\n",
    "\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onoff_from_binary(data, return_duration=True):\n",
    "    \"\"\"Converts a binary variable data into onsets, offsets, and optionally durations\n",
    "\n",
    "    This may yield unexpected behavior if the first value of `data` is true.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like, 1D\n",
    "        binary array from which onsets and offsets should be extracted\n",
    "\n",
    "    \"\"\"\n",
    "    data = data.astype(np.float).copy()\n",
    "    ddata = np.hstack([[0], np.diff(data)])\n",
    "    (onsets,) = np.nonzero(ddata > 0)\n",
    "    # print(onsets)\n",
    "    (offsets,) = np.nonzero(ddata < 0)\n",
    "    # print(offsets)\n",
    "    onset_first = onsets[0] < offsets[0]\n",
    "    len(onsets) == len(offsets)\n",
    "\n",
    "    on_at_end = False\n",
    "    on_at_start = False\n",
    "    if onset_first:\n",
    "        if len(onsets) > len(offsets):\n",
    "            offsets = np.hstack([offsets, [-1]])\n",
    "            on_at_end = True\n",
    "    else:\n",
    "        if len(offsets) > len(onsets):\n",
    "            onsets = np.hstack([-1, offsets])\n",
    "            on_at_start = True\n",
    "    onoff = np.vstack([onsets, offsets])\n",
    "    if return_duration:\n",
    "        duration = offsets - onsets\n",
    "        if on_at_end:\n",
    "            duration[-1] = len(data) - onsets[-1]\n",
    "        if on_at_start:\n",
    "            duration[0] = offsets[0] - 0\n",
    "        onoff = np.vstack([onoff, duration])\n",
    "\n",
    "    onoff = onoff.T.astype(np.int)\n",
    "    return onoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we will be using labeled blink data from gaze in wild. This is one session from Gaze in Wild, with a variety of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = '/home/data/gaze_in_wild/16_1_1.mat'\n",
    "eye_video_file = '/home/data/gaze_in_wild/16_1_1_ds.mp4'\n",
    "pupillometry = dict(np.load('/home/data/gaze_in_wild/pupillometry.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files aren't exactly like files we've dealt with before; two of them store arrays. file_io has a useful function to show what variables are in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_io has a useful function to show what \n",
    "file_io.file_array_keys(label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pupillometry.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here will be to use pupil radius and pupil confidence (from our computed pupil estimate) to predict when blinks occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blink_labels = file_io.load_array(label_file, variable_name='blink').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(blink_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom a little so we can see what's going on - we'll only plot a chunk of the labels that are near 20000 frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blink_region_st = 20000-500\n",
    "blink_region_fin = 20000+500\n",
    "plt.plot(blink_labels[blink_region_st:blink_region_fin])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a useful function to convert binary labels for every timepoint into indices for when the label turns on and turns off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blink_onset_offset = onoff_from_binary(blink_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(blink_onset_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values here are onset frame, offset frame, and duration (in frames)\n",
    "blink_onset_offset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are blinks, right? Let's check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = file_io.load_mp4(eye_video_file, \n",
    "                          size=(30,40), \n",
    "                          frames=blink_onset_offset[2][:2], \n",
    "                          color='gray')\n",
    "\n",
    "anim = plot_utils.make_image_animation(frames, \n",
    "                                       figsize=(3,3),\n",
    "                                       cmap='gray')\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a negative training set: what are NOT blinks? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_examples = []\n",
    "for on, off, duration in blink_onset_offset:\n",
    "    good = False\n",
    "    while not good:\n",
    "        start = np.random.randint(low=0, high=len(blink_labels)-duration)\n",
    "        fin = start + duration\n",
    "        good = np.sum(blink_labels[start:fin]) == 0\n",
    "    negative_examples.append([start, fin, duration])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = file_io.load_mp4(eye_video_file, \n",
    "                          size=(30,40), \n",
    "                          frames=negative_examples[77][:2], \n",
    "                          color='gray')\n",
    "\n",
    "anim = plot_utils.make_image_animation(frames, \n",
    "                                       figsize=(3,3),\n",
    "                                       cmap='gray')\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a blink. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check of how pupilradius matches up with blink epochs for the same time window we looked at above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pupillometry['pupil_radius'][blink_region_st:blink_region_fin], '--', label='pupil radius')\n",
    "# * 10 is just so you can see where the labels are more clearly. \n",
    "plt.plot(blink_labels[blink_region_st:blink_region_fin] * 10, label='blink labels')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pupillometry['pupil_confidence'][blink_region_st:blink_region_fin], '--', label='pupil confidence')\n",
    "plt.plot(blink_labels[blink_region_st:blink_region_fin], label='blink labels')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a classifier based on pupil confidence and eye radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will do the straightforward, perhaps naive thing, and try to \n",
    "# predict every time point that is labeled as a blink\n",
    "positive_trials = [blink_labels[on:off] for on, off, _ in blink_onset_offset]\n",
    "positive_trials = np.hstack(positive_trials)\n",
    "negative_trials = [blink_labels[on:off] for on, off, _ in negative_examples]\n",
    "negative_trials = np.hstack(negative_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.hstack([positive_trials, negative_trials]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will do the straightforward, perhaps naive thing, and try to \n",
    "# predict every time point that is labeled as a blink\n",
    "pupil_radius = pupillometry['pupil_radius']\n",
    "radius_positive = [pupil_radius[on:off] for on, off, _ in blink_onset_offset]\n",
    "radius_positive = np.hstack(radius_positive)\n",
    "radius_negative = [pupil_radius[on:off] for on, off, _ in negative_examples]\n",
    "radius_negative = np.hstack(radius_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will do the straightforward, perhaps naive thing, and try to \n",
    "# predict every time point that is labeled as a blink\n",
    "pupil_confidence = pupillometry['pupil_confidence']\n",
    "confidence_positive = [pupil_confidence[on:off] for on, off, _ in blink_onset_offset]\n",
    "confidence_positive = np.hstack(confidence_positive)\n",
    "confidence_negative = [pupil_confidence[on:off] for on, off, _ in negative_examples]\n",
    "confidence_negative = np.hstack(confidence_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(positive_trials), len(negative_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_positive = len(positive_trials)\n",
    "n_negative = len(negative_trials) # should be the same! \n",
    "\n",
    "trial_labels = np.hstack([positive_trials, negative_trials])\n",
    "\n",
    "trial_features = np.vstack([np.hstack([radius_positive, radius_negative]),\n",
    "                           np.hstack([confidence_positive, confidence_negative])]).T\n",
    "\n",
    "# create a k-fold object\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "overallAccuracy = np.zeros((5,))\n",
    "\n",
    "foldCount = -1\n",
    "# for each train-test split, print the length of train and test indices\n",
    "for train_idx, test_idx in skf.split(trial_features, trial_labels):\n",
    "    #print(train_idx.shape)\n",
    "    #print(test_idx.shape) #pass # print(len(trainIdx), len(testIdx))\n",
    "    foldCount += 1\n",
    "    \n",
    "    # initialize vector that will hold a 1 (accurate) or a 0 (inaccurate) value for each of the test items\n",
    "    foldAccuracy = np.zeros((len(test_idx),))\n",
    "    \n",
    "    # define training data: fill in square brackets to indicate the trial indices for the given fold for training\n",
    "    trainData = trial_features[train_idx]\n",
    "    # define training answers\n",
    "    trainAnswers = trial_labels[train_idx]\n",
    "    \n",
    "    # define testing data: fill in square brackets to indicate the trial indices for the given fold for testing\n",
    "    testData = trial_features[test_idx]\n",
    "    # define testing answers\n",
    "    testAnswers = trial_labels[test_idx]\n",
    "    \n",
    "    print(testData.shape)\n",
    "    # define the classifier\n",
    "    classifier = svm.SVC(kernel = 'linear')\n",
    "    \n",
    "    # train the classifier\n",
    "    classifier.fit(trainData, trainAnswers)\n",
    "    \n",
    "    # test the classifier\n",
    "    predClass = classifier.predict(testData)\n",
    "    \n",
    "    # loop through each of the predicted classes and test whether they are correct\n",
    "    for i in range(len(predClass)):\n",
    "        if predClass[i]==testAnswers[i]: \n",
    "            foldAccuracy[i] = 1\n",
    "            \n",
    "    overallAccuracy[foldCount] = np.mean(foldAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer_workshop",
   "language": "python",
   "name": "summer_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
