{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0142db",
   "metadata": {},
   "source": [
    "# File loading and plotting\n",
    "In this notebook, we will demonstrate how to load and plot a the types of data that we are principally interested in for this course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c51566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "# For fancy HTML movie embedding\n",
    "from IPython.display import HTML\n",
    "\n",
    "# VEDB-specific code imports\n",
    "import file_io\n",
    "import plot_utils\n",
    "\n",
    "# Simple class for loading\n",
    "%run ../../code/sesssion_standalone.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69b3ce",
   "metadata": {},
   "source": [
    "# Data location \n",
    "We will be working with data in a shared folder called `/data/` on phi. (TEMP NOTE for the VEDB team: this data can alos be found on `<vedbcloud0>/data/summer_workshop/data/`) Let's have a look at what's there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74db40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7a476",
   "metadata": {},
   "source": [
    "First we will load data collected for the vedb project, in the /data/vedb/ folder. Each session in this dataset is stored according to the date it was collected; within each folder there are a bunch of video and other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214ab1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls /home/data/vedb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/data/vedb/2021_01_11_16_33_39/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ab5db",
   "metadata": {},
   "source": [
    "Let's load a video first!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97789a",
   "metadata": {},
   "source": [
    "# Simple video loading \n",
    "First we will show you what it would look like to load a video with off-the-shelf tools. Here, we will use OpenCV, but a few other libraries have similar mechanisms to load video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the file you want to load\n",
    "video_file = '/data/vedb/2021_01_11_16_33_39/world.mp4'\n",
    "# Create a video capture object\n",
    "vid = cv2.VideoCapture(video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc59da",
   "metadata": {},
   "source": [
    "This thing we have got is now a python object - a representation of that video. It does NOT actually contain the pixels of the video - so we can't get at them as an array to do computations on yet. We have to use this object to retrieve frames of the video, one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set the first frame you want to read. \n",
    "vid.set(0, 0)\n",
    "# Then, capture a frame. This reads whatever is next in line, after the frame you set above.\n",
    "success, frame = vid.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbcbd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the `success` variable here is True if the frame loaded correctly:\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f85d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `frame` variable contains an array for the image, which has a resolution of 1536 x 2048 pixels\n",
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image!\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdfd388",
   "metadata": {},
   "source": [
    "... wait, what's wrong with the colors? Remember that an image is represnted by (at least) three layers of data, representing the red, green, and blue components of each pixel. Many image formats - and libraries - store and load these as R, G, B (Red, Green, Blue in that order). OpenCV, for whatever reason, loads them as B, G, R. Thus, we have to switch around the order of the color channels to make the image look sensible. \n",
    "\n",
    "This is a really common issue in real data analysis: conventions often differ - even in the same field! - between data sets and code libraries. This will come up in our odometry data, too, and is a common source of confusion in graphics, geospatial analysis, and many other fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423afeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch the image color channels:\n",
    "frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "# Show it again!\n",
    "plt.imshow(frame_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0312e3",
   "metadata": {},
   "source": [
    "Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61256e34",
   "metadata": {},
   "source": [
    "# Loading with a more complex wrapper function\n",
    "This process of opening a movie with opencv works just fine - it's flexible, it's functional, but it's at least three steps, which then have to be run in a loop to load more than one frame. It also doesn't provide any additional functionality, like potentially resizing the frames of the movie at load time (so you don't overrun the RAM of your poor computer with a bajillion pixels). \n",
    "\n",
    "Next we will demonstrate a faster way to load an image with a library written by the instructors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8796da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, specify the video file\n",
    "video_file = '/data/vedb/2021_01_11_16_33_39/world.mp4'\n",
    "# Specify also how many frames you want to load - and that's it! \n",
    "frames = file_io.load_mp4(video_file, frames=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fc1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this loads a whole spatiotemporal chunk of the movie, with frames as the first axis. \n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can index into this to show a frame:\n",
    "plt.imshow(frames[0, :, :, : ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8149cd",
   "metadata": {},
   "source": [
    "Same thing! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b422690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side note: technically, those extra [:] indices are not necessary in python. \n",
    "# So you can show the next frame like this:\n",
    "plt.imshow(frames[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4cc87f",
   "metadata": {},
   "source": [
    "Very slightly different from the first frame! This syntax is nice and clean; it will be used in other notebooks, too. \n",
    "\n",
    "`file_io.load_mp4` provides a few more options too. You can see them by calling help on this function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c41981",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_io.load_mp4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82286967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grayscale, downsampled version of images:\n",
    "gray_frames = file_io.load_mp4(video_file, frames=(0, 10), size=(300,400), color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the color dimension is gone!\n",
    "gray_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image\n",
    "plt.imshow(gray_frames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98f97d",
   "metadata": {},
   "source": [
    "Wait what happened now?? Did we go back to BGR? No - this is just a color map applied to an image with no color channels. To see reglar grayscale colors, you just have to specify a grayscale colormap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d572de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_frames[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can specify other color maps too!\n",
    "plt.imshow(gray_frames[0], cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c8a5d",
   "metadata": {},
   "source": [
    "2D images can be mapped to any color scheme - to see all the colormaps available in matplotlib, check out [this link](https://matplotlib.org/stable/tutorials/colors/colormaps.html)\n",
    "\n",
    "color mapping will be important when we talk about 2D histograms and other quantities computed from images or other data that manifest as arrays! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fbbd82",
   "metadata": {},
   "source": [
    "# VEDB specific loading\n",
    "Finally, we have so many different quantities to load in our VEDB data that it's useful to have a single loader for all the data types. This loader can exploit the fact that within each directory, there is a very regular organization of files. It also can return time-synced data from each stream, as we demonstrate below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"Session\" object from a data folder. Note that you pass the whole folder; the code will figure\n",
    "# out what is inside. This is a bit like the cv2.VideoCapture object above - it isn't the data, it's just\n",
    "# an object that provides a way to load it. \n",
    "ses = Session(folder='/data/vedb/2021_01_11_16_33_39/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9949a5",
   "metadata": {},
   "source": [
    "Here, `ses` is an *instance* of the Session class. It's an object, with properties attached to it and methods that can be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One property is `paths`:\n",
    "ses.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ad066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like vid.read() above, this object has a method to load different streams of data:\n",
    "ses.load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa73d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load world camera data from seconds 8 to 9 in the video:\n",
    "world_time, world_frames = ses.load('world_camera', time_idx=(8,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first data point returned is the timestamp for each frame. For some analyses, this will be important!\n",
    "world_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c69b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that our intended frame rate for our camera is 30 frames per second, but we don't always hit that \n",
    "# for a variety of reasons. If we did, there would be 30 values for world_time, and 30 frames for world_frames:\n",
    "print(world_time.shape)\n",
    "print(world_frames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d07d7",
   "metadata": {},
   "source": [
    "So: not 30 frames per second, but there is one timestamp per frame, so we can compute fps later if we need to. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f02818",
   "metadata": {},
   "source": [
    "Under the hood, this is using file_io, which under the hood is using opencv! Each of these is one more layer of abstraction, providing a little more convenience and a little less flexibility. They are more and more tailored to our uses here. \n",
    "\n",
    "Since this uses file_io.load_mp4 for movies, it can take extra arguments just like `file_io.load_mp4` does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a8420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 10 seconds of downsampled frames\n",
    "world_time, gray_frames = ses.load('world_camera', time_idx=(30,40), color='gray', size=(300, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba897eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(world_time.shape)\n",
    "print(gray_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_frames[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faac42b",
   "metadata": {},
   "source": [
    "The nice thing about this is that we can load the eye data for the same time range! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_left_time, eye_left_frames = ses.load('eye_left', time_idx=(30,40), color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that there are many more frames for the same time interval! \n",
    "# The eye camera has a much faster frame rate than the world camera. \n",
    "print(eye_left_time.shape)\n",
    "print(eye_left_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60475232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here's the eye:\n",
    "plt.imshow(eye_left_frames[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f70c1e",
   "metadata": {},
   "source": [
    "For funz, let's show a movie of the eye data while we're here. This relies on another library written by the instructors, which wraps some matplotlib functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a short 3-second plot, but since the monitor you're on probably can't actually display 200 fps, \n",
    "# show it at a slower rate. Here, 3s worth of eye data will be shown in ~10s\n",
    "fps = 200\n",
    "display_fps = 60\n",
    "seconds = 3\n",
    "anim = plot_utils.make_image_animation(eye_left_frames[:fps * seconds], fps=display_fps, cmap='gray')\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b93b4b",
   "metadata": {},
   "source": [
    "# Loading odometry data\n",
    "The same object and the same method can be used to load odometry data. Odometry data, under the hood, is a very different beast than video data. Each frame of odometry data is stored as a dictionary of values in a special file format called a message pack (msgpack). The method here saves you the trouble of googling around to find an appropriate library to load this data. Note that we won't by default get an array out: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "odometry_time, odometry_all = ses.load('odometry', time_idx=(30,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157bece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this isn't an array, so we can't get its shape - it's a list:\n",
    "print(type(odometry_all))\n",
    "# Note also that odometry is sampled fast, too - nearly 200 fps\n",
    "print(len(odometry_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "odometry_all[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e232f",
   "metadata": {},
   "source": [
    "Each frame has all of these values. It might be more useful for a given analysis to get an array of only one of these out - and the loading function provides such syntax: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7971b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "odometry_time, odometry_linear_velocity = ses.load('odometry:linear_velocity', time_idx=(30,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have an array, which we can plot:\n",
    "print(odometry_linear_velocity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31431e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(odometry_linear_velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea8d91",
   "metadata": {},
   "source": [
    "The same can be done for any of the other odometry parameters, e.g. angular_velocity, angular_acceleration, and position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251aa011",
   "metadata": {},
   "source": [
    "Pogen: not quite sure what to do with this file, let's consult in the morning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02650864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1aa5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrm = pandas.read_csv('/data/odometry/total_acc_x_train.txt', sep='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce0c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088bd7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head /data/odometry/total_acc_x_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec6c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer_workshop",
   "language": "python",
   "name": "summer_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
